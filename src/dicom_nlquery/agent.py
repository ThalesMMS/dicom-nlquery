import json
import logging
from datetime import date
from typing import List, Dict, Any
from .llm_client import OllamaClient
from .agent_tools import DICOM_TOOLS_SCHEMA, execute_tool

log = logging.getLogger(__name__)

SYSTEM_PROMPT = f"""
Voc√™ √© um Agente Especialista em Radiologia. Data: {date.today()}.
Sua fun√ß√£o √© encontrar e recuperar exames m√©dicos complexos.

PROCESSO DE RACIOC√çNIO (ReAct):
1. **BUSCA (Search)**: Use `search_studies` com filtros amplos (sexo, data, modalidade) para achar candidatos.
2. **INSPE√á√ÉO (Inspect)**: O banco de dados N√ÉO sabe o que √© "Esclerose" ou "Contraste".
   - Voc√™ DEVE chamar `inspect_metadata` nos estudos candidatos.
   - LEIA as descri√ß√µes das s√©ries retornadas (SeriesDescription).
   - Procure termos cl√≠nicos como "FLAIR", "T2", "GAD", "+C", "DESMIELINIZANTE".
3. **A√á√ÉO (Act)**: Somente mova (`move_study`) se voc√™ confirmar semanticamente que o exame atende ao pedido.

N√£o invente UIDs. Use apenas os dados retornados.
"""

class DicomAgent:
    def __init__(self, llm: OllamaClient, dicom_client: Any):
        self.llm = llm
        self.client = dicom_client
        self.history = [{"role": "system", "content": SYSTEM_PROMPT}]
        self.max_steps = 10

    def run(self, user_query: str):
        self.history.append({"role": "user", "content": user_query})
        
        for step in range(self.max_steps):
            log.info(f"--- Passo {step+1} ---")
            
            # 1. LLM decide o que fazer
            response = self.llm.chat_with_tools(self.history, tools=DICOM_TOOLS_SCHEMA)
            self.history.append(response) # Guarda o "pensamento"

            # 2. Verifica se a LLM quer usar uma ferramenta
            tool_calls = response.get("tool_calls")
            
            if not tool_calls:
                # Se n√£o chamou ferramenta, √© a resposta final
                return response.get("content")

            # 3. O Python executa cegamente
            for tool in tool_calls:
                fname = tool["function"]["name"]
                fargs = tool["function"]["arguments"]
                if isinstance(fargs, str):
                    fargs = json.loads(fargs)
                
                log.info(f"üîß Agente chamando: {fname}({fargs})")
                
                result = execute_tool(fname, fargs, self.client)
                
                # 4. Devolve a "vis√£o" para a LLM
                self.history.append({
                    "role": "tool",
                    "content": result,
                    "name": fname
                })
        
        return "Limite de passos atingido."