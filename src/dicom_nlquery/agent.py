import json
import logging
import re
from datetime import date
from typing import List, Dict, Any, Optional
from .llm_client import OllamaClient
from .agent_tools import DICOM_TOOLS_SCHEMA, execute_tool

log = logging.getLogger(__name__)

SYSTEM_PROMPT = f"""
Voc√™ √© um Agente Especialista em Radiologia e DICOM. Data: {date.today()}.

REGRAS CR√çTICAS DE OPERA√á√ÉO:
1. **TOOL CALLING**: Use as ferramentas dispon√≠veis. N√£o simule respostas JSON no texto.
2. **OBSTETR√çCIA/FETAL**: Em exames fetais ("feto", "gestante"), o paciente cadastrado geralmente √© a M√ÉE. **NUNCA** filtre por `patient_sex='M'` para fetos. Use 'F' ou remova o filtro de sexo.
3. **SEM ALUCINA√á√ÉO**: Se `search_studies` retornar vazio ("[]"), N√ÉO invente um UID. Sua pr√≥xima a√ß√£o deve ser uma NOVA busca com menos filtros (ex: remover data ou descri√ß√£o).
4. **MODALIDADES**:
   - RM/Resson√¢ncia -> 'MR'
   - TC/Tomografia -> 'CT'
   - RX/Raio-X -> 'CR' ou 'DX'
   - US/Ultrassom -> 'US'
   - "Qualquer exame" -> N√£o preencha o campo modality.
5. **UMA FERRAMENTA POR VEZ**: Em cada turno fa√ßa no m√°ximo 1 tool_call. N√£o chame `inspect_metadata` ou `move_study` junto com `search_studies`; espere o resultado anterior.
6. **UID REAL**: Nunca use placeholders (<...>) ou UIDs inventados. `study_instance_uid` deve vir literalmente de um resultado anterior (apenas d√≠gitos e pontos).
7. **SEXO**: N√£o inferir sexo por g√™nero gramatical ("um/uma"). S√≥ use `patient_sex` se o usu√°rio declarar explicitamente.
8. **RESSON√ÇNCIA**: Se o usu√°rio disser RM/resson√¢ncia/MRI, mantenha `modality=MR`. N√£o troque para US ou outra modalidade.
9. **FETO**: Ao buscar feto/gestante, prefira `study_description="*fet*"` para cobrir ‚Äúfeto/fetal‚Äù.

FLUXO: Search -> (Se vazio: Search Broader) -> (Se achou: Inspect) -> (Se confirmado: Move).
"""

class DicomAgent:
    def __init__(self, llm: OllamaClient, dicom_client: Any):
        self.llm = llm
        self.client = dicom_client
        self.history = [{"role": "system", "content": SYSTEM_PROMPT}]
        self.max_steps = 10

    def _extract_json_from_text(self, text: str) -> Optional[List[Dict]]:
        """
        Rede de seguran√ßa: tenta resgatar chamadas de ferramenta
        quando a LLM escreve o JSON no corpo do texto (alucina√ß√£o de formato).
        """
        try:
            # Procura por padr√µes de JSON de ferramenta no texto: {"name": "...", "parameters": {...}}
            match = re.search(r'(\{\s*"name"\s*:\s*".*?"\s*,\s*"(parameters|arguments)"\s*:\s*\{.*?\}\s*\})', text, re.DOTALL)
            if match:
                json_str = match.group(1)
                data = json.loads(json_str)
                
                # Normaliza campos (alguns modelos usam 'arguments' outros 'parameters')
                fname = data.get("name")
                fargs = data.get("parameters") or data.get("arguments") or {}
                
                if fname:
                    log.warning(f"üïµÔ∏è  Detectado JSON perdido no texto. Convertendo para Tool Call: {fname}")
                    return [{
                        "function": {
                            "name": fname,
                            "arguments": fargs
                        }
                    }]
        except Exception as e:
            pass
        return None

    def _search_signature(self, result_str: str) -> str:
        if not result_str:
            return "EMPTY"
        try:
            data = json.loads(result_str)
        except json.JSONDecodeError:
            return result_str.strip()
        if not isinstance(data, list):
            return result_str.strip()
        uids = []
        for item in data:
            if isinstance(item, dict):
                uid = item.get("UID")
                if uid:
                    uids.append(str(uid).strip())
        if not uids:
            return "EMPTY"
        return "|".join(sorted(uids))

    def run(self, user_query: str):
        self.history.append({"role": "user", "content": user_query})
        search_signature = "NO_SEARCH"
        moved_uids_for_search: set[str] = set()

        for step in range(self.max_steps):
            log.info(f"--- Passo {step+1} ---")
            
            # 1. Chama a LLM
            response = self.llm.chat_with_tools(self.history, tools=DICOM_TOOLS_SCHEMA)
            self.history.append(response)

            tool_calls = response.get("tool_calls")
            content = response.get("content", "") or ""

            # 2. L√≥gica de Fallback (Salva o dia se o JSON vier no texto)
            if not tool_calls and "{" in content:
                rescued = self._extract_json_from_text(content)
                if rescued:
                    tool_calls = rescued

            # Se realmente n√£o tem ferramenta, retorna o texto final
            if not tool_calls:
                return content

            # 3. Executa apenas a primeira ferramenta sugerida; evita sequ√™ncias sem feedback do resultado
            tools_to_run = tool_calls if isinstance(tool_calls, list) else [tool_calls]
            if len(tools_to_run) > 1:
                log.warning(f"‚ö†Ô∏è  LLM retornou {len(tools_to_run)} tool_calls; executando apenas a primeira.")
            tool = tools_to_run[0]
            fname = tool["function"]["name"]
            fargs = tool["function"]["arguments"]
            
            # Garante que args seja dict
            if isinstance(fargs, str):
                try:
                    fargs = json.loads(fargs)
                except json.JSONDecodeError:
                    pass
            
            log.info(f"üîß Agente chamando: {fname}({fargs})")

            # 4. Execu√ß√£o
            if fname == "move_study":
                uid = str(fargs.get("study_instance_uid", "")).strip()
                dest = str(fargs.get("destination_node", "")).strip()
                if uid and dest:
                    if uid in moved_uids_for_search:
                        result_str = (
                            "SKIP: UID ja movido para os resultados atuais. "
                            "Execute nova busca para tentar novamente."
                        )
                        log.info(f"‚Ü©Ô∏è  Ignorando C-MOVE repetido para UID {uid}.")
                        self.history.append({
                            "role": "tool",
                            "content": result_str,
                            "name": fname
                        })
                        self.history.append({
                            "role": "user",
                            "content": "SISTEMA: Nao repita move_study sem nova busca."
                        })
                        continue
                    moved_uids_for_search.add(uid)

            result = execute_tool(fname, fargs, self.client)
            result_str = str(result)
            
            # LOG IMPORTANTE: Ver o que retornou para debug
            preview = (result_str[:150] + '...') if len(result_str) > 150 else result_str
            log.info(f"   ‚Ü≥ Resultado: {preview}")
            
            # 5. Devolve resultado para a LLM
            self.history.append({
                "role": "tool",
                "content": result_str,
                "name": fname
            })

            if fname == "search_studies":
                new_signature = self._search_signature(result_str)
                if new_signature != search_signature:
                    search_signature = new_signature
                    moved_uids_for_search = set()

            # 6. Dica autom√°tica se a busca falhar (Evita loop de desculpas)
            if fname == "search_studies" and ("[]" in result_str or "Nenhum resultado" in result_str):
                log.info("üí° Injetando dica para ampliar busca...")
                self.history.append({
                    "role": "user", 
                    "content": "SISTEMA: A busca retornou vazia. Tente novamente removendo filtros restritivos (como descri√ß√£o, sexo ou data)."
                })

        return "Limite de passos atingido."
